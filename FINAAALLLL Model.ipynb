{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import time\n",
    "#from PIL import Image\n",
    "import mediapipe as mp \n",
    "mpPose = mp.solutions.pose\n",
    "pose = mpPose.Pose()\n",
    "mpDraw = mp.solutions.drawing_utils # For drawing keypoints\n",
    "points = mpPose.PoseLandmark # points will have all 33 landmarks like nose, eyes, ears etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list()\n",
    "data.append('Image')\n",
    "data.append('label')\n",
    "rootdir = \"/home/shikha/POSEESTIMATION/TRAIN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in points: #p will iterate through nose, eyes, ears etc...\n",
    "        x = str(p)[13:]\n",
    "        data.append(x + \"_x\") #will append nose_x\n",
    "        data.append(x + \"_y\") #will append nose_y\n",
    "        data.append(x + \"_z\") #will append nose_z\n",
    "        data.append(x + \"_vis\") #will append nose_vis\n",
    "train_data = pd.DataFrame(columns = data)\n",
    "num_images=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        try:\n",
    "            temp=[]     \n",
    "            imagename=os.path.basename(subdir)\n",
    "            img = cv2.imread(rootdir + \"/\" +imagename+\"/\" +file)\n",
    "            imageWidth, imageHeight = img.shape[:2]\n",
    "            imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            temp.append(subdir)\n",
    "            temp.append(imagename)\n",
    "            results = pose.process(imgRGB)\n",
    "            if results.pose_landmarks:\n",
    "                    mpDraw.draw_landmarks(img, results.pose_landmarks, mpPose.POSE_CONNECTIONS) #draw landmarks on image\n",
    "                    landmarks = results.pose_landmarks.landmark\n",
    "                    for i,j in zip(points,landmarks):\n",
    "                            temp = temp + [j.x, j.y, j.z, j.visibility]\n",
    "            train_data.loc[num_images] = temp\n",
    "            num_images += 1\n",
    "        \n",
    "        except ValueError as ve:\n",
    "            continue \n",
    "train_data.to_csv(\"train_converted.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='poly')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "da = pd.read_csv(\"train_converted.csv\")\n",
    "X,Y= train_data.iloc[:,2:134],train_data['label']\n",
    "svc = SVC(kernel = 'poly')\n",
    "svc.fit(X,Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "Pkl_Filename = \"coordinatemodel.pkl\"  \n",
    "\n",
    "with open(Pkl_Filename, 'wb') as file:  \n",
    "    pickle.dump(svc, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= list()\n",
    "test.append('Image')\n",
    "test.append('label')\n",
    "testdir = \"/home/shikha/POSEESTIMATION/TEST\"\n",
    "\n",
    "for p in points: #p will iterate through nose, eyes, ears etc...\n",
    "        x = str(p)[13:]\n",
    "        test.append(x + \"_x\")\n",
    "        test.append(x + \"_y\")\n",
    "        test.append(x + \"_z\")\n",
    "        test.append(x + \"_vis\")\n",
    "test_data = pd.DataFrame(columns = data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images=0\n",
    "for subdir, dirs, files in os.walk(testdir):\n",
    "    for file in files:\n",
    "        try:\n",
    "            temp=[]   \n",
    "            imagename_test=os.path.basename(subdir)\n",
    "            img_test = cv2.imread(testdir + \"/\" +imagename_test+\"/\" +file)\n",
    "            imageWidth, imageHeight = img_test.shape[:2]\n",
    "            imgRGB = cv2.cvtColor(img_test, cv2.COLOR_BGR2RGB)\n",
    "            temp.append(subdir)\n",
    "            temp.append(imagename_test)\n",
    "            results = pose.process(imgRGB)\n",
    "            if results.pose_landmarks:\n",
    "                    mpDraw.draw_landmarks(img_test, results.pose_landmarks, mpPose.POSE_CONNECTIONS) #draw landmarks on image\n",
    "                    landmarks = results.pose_landmarks.landmark\n",
    "                    for i,j in zip(points,landmarks):\n",
    "                            temp = temp + [j.x, j.y, j.z, j.visibility]\n",
    "            test_data.loc[test_images] = temp\n",
    "            test_images += 1\n",
    "        \n",
    "        except ValueError as ve:\n",
    "            continue \n",
    "test_data.to_csv(\"test_converted.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "clf = GaussianNB()\n",
    "\n",
    "knc=KNeighborsClassifier()\n",
    "\n",
    "rfc=RandomForestClassifier()\n",
    "\n",
    "gbc=GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "S,T= test_data.iloc[:,2:134],test_data['label']\n",
    "models = [svc,clf,knc,rfc,gbc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVC Classifier:\n",
      "\n",
      "Accuracy Score: 0.8769\n",
      "F1_score: 0.8769050410316529\n",
      "\n",
      "Gaussian Naive Bayes:\n",
      "\n",
      "Accuracy Score: 0.5463\n",
      "F1_score: 0.5463071512309496\n",
      "\n",
      "KNeighbors Classifier:\n",
      "\n",
      "Accuracy Score: 0.8054\n",
      "F1_score: 0.8053927315357562\n",
      "\n",
      "Random Forest Classifier:\n",
      "\n",
      "Accuracy Score: 1.0000\n",
      "F1_score: 1.0\n",
      "\n",
      "Gradient Boosting Classifier:\n",
      "\n",
      "Accuracy Score: 1.0000\n",
      "F1_score: 1.0\n"
     ]
    }
   ],
   "source": [
    "for i in models:\n",
    "    if(i==svc):\n",
    "        print(\"\\nSVC Classifier:\\n\")\n",
    "    elif(i==clf):\n",
    "        print(\"\\nGaussian Naive Bayes:\\n\")\n",
    "    elif(i==knc):\n",
    "        print(\"\\nKNeighbors Classifier:\\n\")\n",
    "    elif(i==rfc):\n",
    "        print(\"\\nRandom Forest Classifier:\\n\")\n",
    "    elif(i==gbc):\n",
    "        print(\"\\nGradient Boosting Classifier:\\n\")   \n",
    "    modelfit = i.fit(S,T)\n",
    "    pred=i.predict(S)\n",
    "    acc=accuracy_score(T,pred)\n",
    "    f1=f1_score(T, pred, average='micro')\n",
    "    print (\"Accuracy Score: {0:.4f}\".format(acc))\n",
    "    print(\"F1_score:\",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
